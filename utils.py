# utils.py
import requests
import xml.etree.ElementTree as ET
import pandas as pd
import json
from tkinter import filedialog, messagebox

def load_config(config_path: str = 'config.json') -> dict:
    """Loads configuration from a JSON file."""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        messagebox.showerror("Chyba konfigurácie", f"Konfiguračný súbor '{config_path}' nebol nájdený.")
        return {}
    except json.JSONDecodeError:
        messagebox.showerror("Chyba konfigurácie", f"Chyba pri parsovaní súboru '{config_path}'. Skontrolujte syntax JSON.")
        return {}

def load_csv_data(file_path: str) -> pd.DataFrame:
    """Loads CSV data from the given path into a Pandas DataFrame, considering semicolon as separator and comma as decimal point."""
    try:
        # Try these encoding options sequentially:

        # 1. Most common for Slovak environment: cp1250
        df = pd.read_csv(
            file_path,
            sep=';',
            decimal=',',
            encoding='cp1250',
            on_bad_lines='skip'
        )
        return df
    except UnicodeDecodeError:
        try:
            # 2. Another common option for Central Europe: latin1
            df = pd.read_csv(
                file_path,
                sep=';',
                decimal=',',
                encoding='latin1',
                on_bad_lines='skip'
            )
            return df
        except UnicodeDecodeError:
            try:
                # 3. If CSV is generated by Excel and has BOM: utf-8-sig
                df = pd.read_csv(
                    file_path,
                    sep=';',
                    decimal=',',
                    encoding='utf-8-sig',
                    on_bad_lines='skip'
                )
                return df
            except Exception as e:
                messagebox.showerror("Chyba načítania CSV", f"Nepodarilo sa načítať CSV súbor. Skontrolujte kódovanie a formát.\nChyba: {e}")
                return pd.DataFrame()
    except Exception as e: # Catches other errors besides encoding
        messagebox.showerror("Chyba načítania CSV", f"Nepodarilo sa načítať CSV súbor. Skontrolujte formát.\nChyba: {e}")
        return pd.DataFrame() # Returns empty DataFrame on error    

def fetch_xml_feed(url: str) -> ET.Element:
    """Downloads XML feed from the given URL and returns the root element."""
    try:
        print(f"Attempting to fetch XML feed from URL: {url}")
        response = requests.get(url, timeout=30)
        
        # Print response status and information for debugging
        print(f"Response status code: {response.status_code}")
        print(f"Response content type: {response.headers.get('Content-Type', 'unknown')}")
        print(f"Response size: {len(response.content)} bytes")
        
        # Show first 200 characters of response to check if it looks like XML
        content_preview = response.content[:200].decode('utf-8', errors='replace')
        print(f"Content preview: {content_preview}")
        
        response.raise_for_status()
        
        try:
            root = ET.fromstring(response.content)
            print(f"Successfully parsed XML, root tag: {root.tag}")
            return root
        except ET.ParseError as xml_error:
            print(f"XML parsing error: {xml_error}")
            messagebox.showwarning("Chyba pri parsovaní XML", f"Získaný obsah z {url} nie je platný XML.\nChyba: {xml_error}")
            return None
            
    except requests.exceptions.RequestException as e:
        print(f"Request error for {url}: {e}")
        messagebox.showwarning("Chyba pri sťahovaní feedu", f"Nepodarilo sa stiahnuť XML feed z {url}. Pokračujem bez neho.\nChyba: {e}")
        return None

def parse_xml_feed(root: ET.Element, root_element_tag: str, mapping: dict) -> pd.DataFrame:
    """
    Parses XML root element and transforms it into a Pandas DataFrame
    according to the provided mapping and root element tag of the product.
    """
    if root is None:
        return pd.DataFrame()

    data = []
    # Find all elements that represent a single product
    for item in root.findall(f".//{root_element_tag}"):
        row = {}
        for xml_key, csv_column in mapping.items():
            # If the key is compound (e.g., "images/item/url"), use findall and join values
            if '/' in xml_key:
                elements = item.findall(xml_key)
                if elements:
                    # Join all found URL addresses into one string separated by commas
                    row[csv_column] = ", ".join([el.text.strip() for el in elements if el.text])
                else:
                    row[csv_column] = None
            else:
                element = item.find(xml_key)
                row[csv_column] = element.text.strip() if element is not None and element.text is not None else None
        data.append(row)
    
    df = pd.DataFrame(data)
    
    # Ensure that DataFrame has all columns defined in mapping
    missing_cols = set(mapping.values()) - set(df.columns)
    for col in missing_cols:
        df[col] = None
        
    # Return DataFrame with only columns defined in mapping
    return df[list(mapping.values())]

def merge_dataframes(main_df: pd.DataFrame, feed_dfs: list, final_cols: list) -> pd.DataFrame:
    """
    Merges data from the main DataFrame and a list of DataFrames from feeds.
    Priority: Gastropro CSV (main_df) > Feed1 > Feed2 > etc.
    
    Universal solution to handle any columns regardless of presence in feeds.
    Joins on 'Kat. číslo' (catalog number) as the primary key.
    """
    # Start with a copy of the main dataframe, ensuring all final columns exist
    merged_df = main_df.copy()
    
    # First make sure the main dataframe has all necessary columns for the final output
    for col in final_cols:
        if col not in merged_df.columns:
            merged_df[col] = ""  # Add missing columns with empty string
    
    # Define the join column
    join_column = "Kat. číslo"  # Catalog number as primary key for joining
            
    # Process feeds in order of priority (lower index = higher priority)
    for i, df_from_feed in enumerate(feed_dfs):
        # Skip empty dataframes
        if df_from_feed.empty:
            print(f"Feed {i+1} is empty, skipping.")
            continue
        
        # No join needed if feed has no data
        if len(df_from_feed) == 0:
            print(f"Feed {i+1} has no rows, skipping.")
            continue
            
        try:
            # Check if we can join by catalog number
            if join_column in df_from_feed.columns and join_column in merged_df.columns:
                # Standard join on catalog number
                feed_suffix = f'_feed{i+1}'
                
                # First clean up any NaN values in the join column
                merged_df[join_column] = merged_df[join_column].fillna("")
                df_from_feed[join_column] = df_from_feed[join_column].fillna("")
                
                # Debug the join values to see what might match
                print(f"Join column '{join_column}' sample values in main DF: {merged_df[join_column].unique()[:5]}")
                print(f"Join column '{join_column}' sample values in feed: {df_from_feed[join_column].unique()[:5]}")
                
                # Use outer join to include ALL products from both sources
                # 'outer' will include rows that appear in EITHER DataFrame
                temp_df = pd.merge(merged_df, df_from_feed, on=join_column, how="outer", suffixes=('', feed_suffix))
                
                # Find columns from the feed (those with the suffix)
                feed_suffix_columns = [col for col in temp_df.columns if col.endswith(feed_suffix)]
                
                # For each feed column, fill NaN values in the corresponding original column
                for feed_col in feed_suffix_columns:
                    original_col = feed_col.replace(feed_suffix, '')
                    if original_col in temp_df.columns:
                        # Fill NaN values in original column with values from feed column
                        temp_df[original_col] = temp_df[original_col].fillna(temp_df[feed_col])
                    
                    # Remove the feed suffixed column after using its values
                    temp_df = temp_df.drop(columns=[feed_col])
                    
                # Update the merged dataframe
                merged_df = temp_df
            else:
                # Alternative approach for feeds missing the join column
                print(f"Feed {i+1} or main dataframe doesn't have '{join_column}' column for joining. Handling columns individually.")
                
                # Add all columns from feed to the main dataframe
                for col in df_from_feed.columns:
                    if col in final_cols and col not in merged_df.columns:
                        # This is a new column we want in the output
                        merged_df[col] = ""
                    elif col in final_cols:
                        # This is a column we already have, but maybe with empty values
                        # Copy non-empty values from feed to fill empty spots in main df
                        for idx in merged_df.index:
                            if pd.isna(merged_df.at[idx, col]) or merged_df.at[idx, col] == "":
                                # Try to find a non-empty value in the feed
                                if len(df_from_feed) > 0:  # Only attempt if feed has data
                                    # Take the first non-empty value we find (or empty if none found)
                                    feed_val = df_from_feed[col].dropna().iloc[0] if not df_from_feed[col].dropna().empty else ""
                                    merged_df.at[idx, col] = feed_val
        
        except Exception as e:
            print(f"Error processing feed {i+1}: {str(e)}")
            # Continue with next feed despite the error
            continue

    # Make sure all required columns exist in the final output
    for col in final_cols:
        if col not in merged_df.columns:
            merged_df[col] = ""  # Add any missing columns with empty string
    
    # Handle any remaining NaN values by converting to empty string
    result_df = merged_df[final_cols].fillna("")
    
    return result_df